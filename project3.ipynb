{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2d39e92f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime as dt\n",
    "from calendar import monthrange\n",
    "import s3fs\n",
    "import xarray as xr\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e0bc27c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_water_data(sat: str, lyr: int, idyjl: int, band: int = 9):\n",
    "    \"\"\"\n",
    "    Gets GOES water vapor data from AWS S3.\n",
    "\n",
    "    Args:\n",
    "        sat: 'goes-east' (GOES-16), 'goes-west' (GOES-17/18)\n",
    "        yr: Year (2025)\n",
    "        ldyjl: Julian day (1-365)\n",
    "        band: ABI band (8=upper-level, 9=mid-level, 10=lower-level)\n",
    "    \n",
    "    Return:\n",
    "        xarray.Dataset of the selected day's water vapor imagery.\n",
    "    \"\"\"\n",
    "\n",
    "    #converts julian data to date-time\n",
    "    d = dt.datetime(lyr,1,1) + dt.timedelta(days=idyjl - 1)\n",
    "    #connects to s3 bucket\n",
    "    fs = s3fs.S3FileSystem(anon=True)\n",
    "    \n",
    "    imon,idym=d.month,d.day\n",
    "    syr,sjdy,smon,sdym = str(lyr).zfill(4),str(idyjl).zfill(3),str(imon).zfill(2),str(idym).zfill(2)\n",
    "    \n",
    "    # Choose bucket\n",
    "    sat_bucket = 'noaa-goes16' if sat == 'goes-east' else 'noaa-goes17'\n",
    "    sat_bucket = 'noaa-goes16' if sat == 'goes-east' else \"noaa-goes19\"\n",
    "\n",
    "    # Path to GOES ABI L2 CMIP (Cloud & Moisture Imagery)\n",
    "    path_pattern = f\"s3://{sat_bucket}/ABI-L2-CMIPF/{syr}/{sjdy}/*/OR_ABI-L2-CMIPF-M6C{str(band).zfill(2)}*.nc\"\n",
    "\n",
    "    # List files and limit\n",
    "    file_location = fs.glob(path_pattern)[:3]\n",
    "    var = 'CMI'\n",
    "    if not file_location:\n",
    "        raise FileNotFoundError(f\"No files found for pattern: {path_pattern}\")\n",
    "\n",
    "    file_ob = [fs.open(file) for file in file_location]        #open connection to files\n",
    "    \n",
    "    #open all the day's data\n",
    "    ds = xr.open_mfdataset(file_ob,combine='nested',concat_dim='time') #note file is super messed up formatting\n",
    "\n",
    "    ds['BT'] = ds[var]\n",
    "    ds['BT'].attrs['units'] = 'Kelvin'\n",
    "    ds['BT'].attrs['long_name'] = 'Brightness Temperature / CMI'\n",
    "    \n",
    "    return ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01955eac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No data for 2025-11-12 (goes-19) — skipping\n",
      "No data for 2025-11-13 (goes-19) — skipping\n",
      "No data for 2025-11-14 (goes-19) — skipping\n",
      "No data for 2025-11-15 (goes-19) — skipping\n",
      "No data for 2025-11-16 (goes-19) — skipping\n",
      "No data for 2025-11-17 (goes-19) — skipping\n",
      "No data for 2025-11-18 (goes-19) — skipping\n",
      "No data for 2025-11-19 (goes-19) — skipping\n",
      "No data for 2025-11-20 (goes-19) — skipping\n",
      "No data for 2025-11-21 (goes-19) — skipping\n",
      "No data for 2025-11-22 (goes-19) — skipping\n",
      "No data for 2025-11-23 (goes-19) — skipping\n",
      "No data for 2025-11-24 (goes-19) — skipping\n",
      "No data for 2025-11-25 (goes-19) — skipping\n",
      "No data for 2025-11-26 (goes-19) — skipping\n",
      "No data for 2025-11-27 (goes-19) — skipping\n",
      "No data for 2025-11-28 (goes-19) — skipping\n",
      "No data for 2025-11-29 (goes-19) — skipping\n",
      "No data for 2025-11-30 (goes-19) — skipping\n",
      "No data for 2025-12-01 (goes-19) — skipping\n",
      "No data for 2025-12-02 (goes-19) — skipping\n",
      "No data for 2025-12-03 (goes-19) — skipping\n",
      "No data for 2025-12-04 (goes-19) — skipping\n",
      "No data for 2025-12-05 (goes-19) — skipping\n",
      "No data for 2025-12-06 (goes-19) — skipping\n",
      "No data for 2025-12-07 (goes-19) — skipping\n",
      "No data for 2025-12-08 (goes-19) — skipping\n",
      "No data for 2025-12-09 (goes-19) — skipping\n",
      "No data for 2025-12-10 (goes-19) — skipping\n",
      "No data for 2025-12-11 (goes-19) — skipping\n",
      "No data for 2025-12-12 (goes-19) — skipping\n",
      "No data for 2025-12-13 (goes-19) — skipping\n",
      "No data for 2025-12-14 (goes-19) — skipping\n",
      "No data for 2025-12-15 (goes-19) — skipping\n",
      "No data for 2025-12-16 (goes-19) — skipping\n",
      "No data for 2025-12-17 (goes-19) — skipping\n",
      "No data for 2025-12-18 (goes-19) — skipping\n",
      "No data for 2025-12-19 (goes-19) — skipping\n",
      "No data for 2025-12-20 (goes-19) — skipping\n",
      "No data for 2025-12-21 (goes-19) — skipping\n",
      "No data for 2025-12-22 (goes-19) — skipping\n",
      "No data for 2025-12-23 (goes-19) — skipping\n",
      "No data for 2025-12-24 (goes-19) — skipping\n",
      "No data for 2025-12-25 (goes-19) — skipping\n",
      "No data for 2025-12-26 (goes-19) — skipping\n",
      "No data for 2025-12-27 (goes-19) — skipping\n",
      "No data for 2025-12-28 (goes-19) — skipping\n",
      "No data for 2025-12-29 (goes-19) — skipping\n",
      "No data for 2025-12-30 (goes-19) — skipping\n",
      "No data for 2025-12-31 (goes-19) — skipping\n"
     ]
    }
   ],
   "source": [
    "regions = {\n",
    "    \"Western Hemisphere\": {\"x_min\": 0, \"x_max\": 2700, \"y_min\": 0, \"y_max\": 5424},\n",
    "    \"Tropics\": {\"x_min\": 1000, \"x_max\": 4400, \"y_min\": 2000, \"y_max\": 3400},\n",
    "    \"North America\": {\"x_min\": 1000, \"x_max\": 2200, \"y_min\": 3000, \"y_max\": 4400},\n",
    "    \"South America\": {\"x_min\": 1200, \"x_max\": 2600, \"y_min\": 1000, \"y_max\": 3000}\n",
    "}\n",
    "\n",
    "# Choose satellite automatically\n",
    "def get_satellite_for_date(date):\n",
    "    \"\"\"GOES-16 through April 7 2025 (day 97), then GOES-19.\"\"\"\n",
    "    return 'goes-east' if date.timetuple().tm_yday <= 97 else 'goes-19'\n",
    "\n",
    "daily_csv = \"goes16_water_vapor_regions_daily_2025_band_9.csv\"\n",
    "daily_data = []\n",
    "\n",
    "# If CSV already exists, load it to continue appending\n",
    "try:\n",
    "    df_existing = pd.read_csv(daily_csv, parse_dates=[\"date\"])\n",
    "    last_date = df_existing[\"date\"].max().date()\n",
    "    start_day = (last_date - dt.date(2025, 1, 1)).days + 2\n",
    "    daily_data = df_existing.to_dict(\"records\")\n",
    "    print(f\"Starting from {last_date + dt.timedelta(days=1)} (day {start_day})\")\n",
    "except FileNotFoundError:\n",
    "    start_day = 1\n",
    "\n",
    "# Collect daily data\n",
    "for day_of_year in range(start_day, 366):\n",
    "    date = dt.datetime(2025, 1, 1) + dt.timedelta(days=day_of_year - 1)\n",
    "    satellite = get_satellite_for_date(date)\n",
    "\n",
    "    try:\n",
    "        ds = get_water_data(satellite, 2025, day_of_year, band=8)\n",
    "    except FileNotFoundError:\n",
    "        print(f\"No data for {date.date()} ({satellite}) — skipping\")\n",
    "        continue\n",
    "\n",
    "    for region_name, bbox in regions.items():\n",
    "        region_ds = ds.isel(\n",
    "            x=slice(bbox[\"x_min\"], bbox[\"x_max\"]),\n",
    "            y=slice(bbox[\"y_min\"], bbox[\"y_max\"])\n",
    "        )\n",
    "\n",
    "        mean_bt = float(region_ds[\"BT\"].mean())\n",
    "        min_bt = float(region_ds[\"BT\"].min())\n",
    "        max_bt = float(region_ds[\"BT\"].max())\n",
    "\n",
    "        record = {\n",
    "            \"date\": date.date(),\n",
    "            \"region\": region_name,\n",
    "            \"mean_BT\": mean_bt,\n",
    "            \"min_BT\": min_bt,\n",
    "            \"max_BT\": max_bt\n",
    "        }\n",
    "        daily_data.append(record)\n",
    "\n",
    "        # pd.DataFrame(daily_data).to_csv(daily_csv, index=False)\n",
    "\n",
    "# Make weekly summary\n",
    "df = pd.DataFrame(daily_data)\n",
    "df[\"date\"] = pd.to_datetime(df[\"date\"])\n",
    "df[\"week\"] = df[\"date\"].dt.isocalendar().week\n",
    "\n",
    "weekly_df = (\n",
    "    df.groupby([\"week\", \"region\"])\n",
    "      .agg({\n",
    "          \"mean_BT\": \"mean\",\n",
    "          \"min_BT\": \"min\",\n",
    "          \"max_BT\": \"max\"\n",
    "      })\n",
    "      .reset_index()\n",
    ")\n",
    "\n",
    "weekly_df[\"week_start_date\"] = (\n",
    "    pd.to_datetime(\"2025-01-01\") + pd.to_timedelta((weekly_df[\"week\"] - 1) * 7, unit=\"d\")\n",
    ")\n",
    "\n",
    "# weekly_df.to_csv(\"goes16_water_vapor_regions_weekly_2025_band_8.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a16b824f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
